Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=56, c_out=7, checkpoints='./checkpoints/', d_ff=237, d_layers=1, d_model=240, data='custom', data_path='exchange_rate.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', dishts=0, distil=True, do_predict=False, dropout=0.3, e_layers=1, embed='timeF', embed_type=0, enc_in=8, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, hidden_size=[12, 15], hidden_size1=3, hidden_size2=3, individual=0, is_training=1, itr=1, k=1.0, kernel_size=25, label_len=18, learning_rate=0.00469, loss='mse', lradj='type3', model='SPM_TST', model_id='96_192', moving_avg=25, n_heads=1, num_layers=3, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=20, pct_start=0.3, pred_len=192, random_seed=2021, revin=1, root_path='./dataset/', seq_len=96, stride=8, subtract_last=0, target='OT', test_flop=False, traffic=0, train_epochs=300, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : 96_192_SPM_TST_custom_ftM_sl96_ll18_pl192_dm240_nh1_el1_dl1_df237_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 5024
val 569
test 1326
Epoch: 1 cost time: 1.6681995391845703
Epoch: 1, Steps: 89 | Train Loss: 0.2582519 Vali Loss: 0.2295318 Test Loss: 0.1638406
Validation loss decreased (inf --> 0.229532).  Saving model ...
Updating learning rate to 0.00469
Epoch: 2 cost time: 1.26283597946167
Epoch: 2, Steps: 89 | Train Loss: 0.2552410 Vali Loss: 0.2638882 Test Loss: 0.2000214
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00469
Epoch: 3 cost time: 1.260028600692749
Epoch: 3, Steps: 89 | Train Loss: 0.2404184 Vali Loss: 0.2848021 Test Loss: 0.2065015
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00469
Epoch: 4 cost time: 1.3220057487487793
Epoch: 4, Steps: 89 | Train Loss: 0.2326444 Vali Loss: 0.2884743 Test Loss: 0.2183369
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.004221
Epoch: 5 cost time: 2.3275253772735596
Epoch: 5, Steps: 89 | Train Loss: 0.2216529 Vali Loss: 0.2827863 Test Loss: 0.2374756
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0037989
Epoch: 6 cost time: 1.2764995098114014
Epoch: 6, Steps: 89 | Train Loss: 0.2131534 Vali Loss: 0.2924548 Test Loss: 0.2152168
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00341901
Epoch: 7 cost time: 1.4644889831542969
Epoch: 7, Steps: 89 | Train Loss: 0.2001590 Vali Loss: 0.3431332 Test Loss: 0.2250255
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.0030771089999999997
Epoch: 8 cost time: 1.3222968578338623
Epoch: 8, Steps: 89 | Train Loss: 0.1897522 Vali Loss: 0.3797237 Test Loss: 0.2407165
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.0027693981
Epoch: 9 cost time: 1.404541015625
Epoch: 9, Steps: 89 | Train Loss: 0.1795450 Vali Loss: 0.3520861 Test Loss: 0.2272535
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00249245829
Epoch: 10 cost time: 1.3198819160461426
Epoch: 10, Steps: 89 | Train Loss: 0.1717259 Vali Loss: 0.3511873 Test Loss: 0.2392429
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.0022432124610000004
Epoch: 11 cost time: 1.2765629291534424
Epoch: 11, Steps: 89 | Train Loss: 0.1663297 Vali Loss: 0.4005341 Test Loss: 0.2553636
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.0020188912149000002
Epoch: 12 cost time: 1.3040080070495605
Epoch: 12, Steps: 89 | Train Loss: 0.1617984 Vali Loss: 0.3667591 Test Loss: 0.2376590
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0018170020934100003
Epoch: 13 cost time: 1.3081965446472168
Epoch: 13, Steps: 89 | Train Loss: 0.1517209 Vali Loss: 0.4078740 Test Loss: 0.2394316
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.0016353018840690003
Epoch: 14 cost time: 1.3379895687103271
Epoch: 14, Steps: 89 | Train Loss: 0.1440827 Vali Loss: 0.3905289 Test Loss: 0.2539831
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0014717716956621002
Epoch: 15 cost time: 1.3143155574798584
Epoch: 15, Steps: 89 | Train Loss: 0.1393549 Vali Loss: 0.3835723 Test Loss: 0.2555703
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.0013245945260958905
Epoch: 16 cost time: 1.3784043788909912
Epoch: 16, Steps: 89 | Train Loss: 0.1326080 Vali Loss: 0.4033502 Test Loss: 0.2523613
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0011921350734863012
Epoch: 17 cost time: 1.300769567489624
Epoch: 17, Steps: 89 | Train Loss: 0.1254584 Vali Loss: 0.3943872 Test Loss: 0.2461788
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.0010729215661376714
Epoch: 18 cost time: 1.247509479522705
Epoch: 18, Steps: 89 | Train Loss: 0.1218787 Vali Loss: 0.3952173 Test Loss: 0.2525001
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.0009656294095239041
Epoch: 19 cost time: 2.2929859161376953
Epoch: 19, Steps: 89 | Train Loss: 0.1176987 Vali Loss: 0.3738306 Test Loss: 0.2370878
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.0008690664685715137
Epoch: 20 cost time: 1.3829715251922607
Epoch: 20, Steps: 89 | Train Loss: 0.1130660 Vali Loss: 0.3909313 Test Loss: 0.2362864
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.0007821598217143624
Epoch: 21 cost time: 1.341897964477539
Epoch: 21, Steps: 89 | Train Loss: 0.1093747 Vali Loss: 0.3695521 Test Loss: 0.2473882
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : 96_192_SPM_TST_custom_ftM_sl96_ll18_pl192_dm240_nh1_el1_dl1_df237_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1326
mse:0.1638406217098236, mae:0.28868013620376587, rse:0.3127894699573517
