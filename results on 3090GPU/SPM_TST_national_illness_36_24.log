Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=58, c_out=7, checkpoints='./checkpoints/', d_ff=114, d_layers=1, d_model=139, data='custom', data_path='national_illness.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', dishts=1, distil=True, do_predict=False, dropout=0.3, e_layers=1, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, hidden_size=[6, 6], hidden_size1=3, hidden_size2=3, individual=0, is_training=1, itr=1, k=1.0, kernel_size=25, label_len=18, learning_rate=0.00055, loss='mse', lradj='constant', model='SPM_TST', model_id='36_24', moving_avg=25, n_heads=1, num_layers=3, num_workers=10, output_attention=False, padding_patch='end', patch_len=24, patience=20, pct_start=0.3, pred_len=24, random_seed=2021, revin=1, root_path='./dataset/', seq_len=36, stride=2, subtract_last=0, target='OT', test_flop=False, topk=49, traffic=0, train_epochs=300, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : 36_24_SPM_TST_custom_ftM_sl36_ll18_pl24_dm139_nh1_el1_dl1_df114_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 617
val 74
test 170
Epoch: 1 cost time: 0.6483573913574219
Epoch: 1, Steps: 10 | Train Loss: 1.0620449 Vali Loss: 0.9826705 Test Loss: 3.9972785
Validation loss decreased (inf --> 0.982671).  Saving model ...
Updating learning rate to 0.00055
Epoch: 2 cost time: 0.4250948429107666
Epoch: 2, Steps: 10 | Train Loss: 0.8212279 Vali Loss: 0.4424403 Test Loss: 2.0360279
Validation loss decreased (0.982671 --> 0.442440).  Saving model ...
Updating learning rate to 0.00055
Epoch: 3 cost time: 0.4703216552734375
Epoch: 3, Steps: 10 | Train Loss: 0.6995196 Vali Loss: 0.4409672 Test Loss: 2.0834913
Validation loss decreased (0.442440 --> 0.440967).  Saving model ...
Updating learning rate to 0.00055
Epoch: 4 cost time: 0.5303030014038086
Epoch: 4, Steps: 10 | Train Loss: 0.6256132 Vali Loss: 0.3346126 Test Loss: 1.7221918
Validation loss decreased (0.440967 --> 0.334613).  Saving model ...
Updating learning rate to 0.00055
Epoch: 5 cost time: 0.44505929946899414
Epoch: 5, Steps: 10 | Train Loss: 0.5882725 Vali Loss: 0.2627507 Test Loss: 1.3888404
Validation loss decreased (0.334613 --> 0.262751).  Saving model ...
Updating learning rate to 0.00055
Epoch: 6 cost time: 0.46663975715637207
Epoch: 6, Steps: 10 | Train Loss: 0.5192086 Vali Loss: 0.2761370 Test Loss: 1.3916979
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00055
Epoch: 7 cost time: 0.47277402877807617
Epoch: 7, Steps: 10 | Train Loss: 0.4982305 Vali Loss: 0.2393862 Test Loss: 1.2058983
Validation loss decreased (0.262751 --> 0.239386).  Saving model ...
Updating learning rate to 0.00055
Epoch: 8 cost time: 0.4733257293701172
Epoch: 8, Steps: 10 | Train Loss: 0.4626326 Vali Loss: 0.2269178 Test Loss: 1.0005010
Validation loss decreased (0.239386 --> 0.226918).  Saving model ...
Updating learning rate to 0.00055
Epoch: 9 cost time: 0.46849703788757324
Epoch: 9, Steps: 10 | Train Loss: 0.4408181 Vali Loss: 0.2347365 Test Loss: 1.3339279
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00055
Epoch: 10 cost time: 0.47979140281677246
Epoch: 10, Steps: 10 | Train Loss: 0.4393711 Vali Loss: 0.2357250 Test Loss: 1.0047809
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00055
Epoch: 11 cost time: 0.47719407081604004
Epoch: 11, Steps: 10 | Train Loss: 0.4078103 Vali Loss: 0.2092352 Test Loss: 0.9402290
Validation loss decreased (0.226918 --> 0.209235).  Saving model ...
Updating learning rate to 0.00055
Epoch: 12 cost time: 0.4857442378997803
Epoch: 12, Steps: 10 | Train Loss: 0.3897256 Vali Loss: 0.2060410 Test Loss: 1.1148160
Validation loss decreased (0.209235 --> 0.206041).  Saving model ...
Updating learning rate to 0.00055
Epoch: 13 cost time: 0.45923829078674316
Epoch: 13, Steps: 10 | Train Loss: 0.3820576 Vali Loss: 0.2151014 Test Loss: 0.9932747
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00055
Epoch: 14 cost time: 0.4741482734680176
Epoch: 14, Steps: 10 | Train Loss: 0.3573376 Vali Loss: 0.2259180 Test Loss: 0.9545891
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00055
Epoch: 15 cost time: 0.4609358310699463
Epoch: 15, Steps: 10 | Train Loss: 0.3342660 Vali Loss: 0.2050286 Test Loss: 1.1848729
Validation loss decreased (0.206041 --> 0.205029).  Saving model ...
Updating learning rate to 0.00055
Epoch: 16 cost time: 0.4557638168334961
Epoch: 16, Steps: 10 | Train Loss: 0.3192404 Vali Loss: 0.2489030 Test Loss: 0.9169040
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00055
Epoch: 17 cost time: 0.45513200759887695
Epoch: 17, Steps: 10 | Train Loss: 0.3243922 Vali Loss: 0.2073096 Test Loss: 1.0258476
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00055
Epoch: 18 cost time: 0.43463587760925293
Epoch: 18, Steps: 10 | Train Loss: 0.3121479 Vali Loss: 0.2196525 Test Loss: 0.8686157
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00055
Epoch: 19 cost time: 0.4936983585357666
Epoch: 19, Steps: 10 | Train Loss: 0.2844731 Vali Loss: 0.1971942 Test Loss: 0.9920889
Validation loss decreased (0.205029 --> 0.197194).  Saving model ...
Updating learning rate to 0.00055
Epoch: 20 cost time: 0.4958174228668213
Epoch: 20, Steps: 10 | Train Loss: 0.2913260 Vali Loss: 0.2250007 Test Loss: 1.0888596
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00055
Epoch: 21 cost time: 0.5250167846679688
Epoch: 21, Steps: 10 | Train Loss: 0.2825392 Vali Loss: 0.2399649 Test Loss: 0.7589091
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00055
Epoch: 22 cost time: 0.4637153148651123
Epoch: 22, Steps: 10 | Train Loss: 0.2693888 Vali Loss: 0.2182319 Test Loss: 1.0105563
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00055
Epoch: 23 cost time: 0.5234260559082031
Epoch: 23, Steps: 10 | Train Loss: 0.2560150 Vali Loss: 0.2019940 Test Loss: 0.9859711
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00055
Epoch: 24 cost time: 0.5127801895141602
Epoch: 24, Steps: 10 | Train Loss: 0.2672018 Vali Loss: 0.2397288 Test Loss: 0.9164870
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00055
Epoch: 25 cost time: 0.5070357322692871
Epoch: 25, Steps: 10 | Train Loss: 0.2558069 Vali Loss: 0.2068222 Test Loss: 0.8812562
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00055
Epoch: 26 cost time: 0.5086562633514404
Epoch: 26, Steps: 10 | Train Loss: 0.2390536 Vali Loss: 0.2068479 Test Loss: 0.9722328
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00055
Epoch: 27 cost time: 0.4517025947570801
Epoch: 27, Steps: 10 | Train Loss: 0.2384708 Vali Loss: 0.2309504 Test Loss: 0.8118966
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00055
Epoch: 28 cost time: 0.4495522975921631
Epoch: 28, Steps: 10 | Train Loss: 0.2285022 Vali Loss: 0.2208825 Test Loss: 0.9358191
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00055
Epoch: 29 cost time: 0.4909532070159912
Epoch: 29, Steps: 10 | Train Loss: 0.2223124 Vali Loss: 0.2055442 Test Loss: 0.8362068
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00055
Epoch: 30 cost time: 0.4720134735107422
Epoch: 30, Steps: 10 | Train Loss: 0.2242374 Vali Loss: 0.1909557 Test Loss: 0.7710029
Validation loss decreased (0.197194 --> 0.190956).  Saving model ...
Updating learning rate to 0.00055
Epoch: 31 cost time: 0.5121662616729736
Epoch: 31, Steps: 10 | Train Loss: 0.2199840 Vali Loss: 0.1916183 Test Loss: 1.1560893
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00055
Epoch: 32 cost time: 0.4833109378814697
Epoch: 32, Steps: 10 | Train Loss: 0.2256827 Vali Loss: 0.2286178 Test Loss: 0.7535264
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00055
Epoch: 33 cost time: 0.475538969039917
Epoch: 33, Steps: 10 | Train Loss: 0.2162483 Vali Loss: 0.2313001 Test Loss: 0.9321762
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.00055
Epoch: 34 cost time: 0.5220470428466797
Epoch: 34, Steps: 10 | Train Loss: 0.2110496 Vali Loss: 0.2316187 Test Loss: 0.9273043
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.00055
Epoch: 35 cost time: 0.4908311367034912
Epoch: 35, Steps: 10 | Train Loss: 0.2056883 Vali Loss: 0.2457129 Test Loss: 0.8121545
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00055
Epoch: 36 cost time: 0.4623427391052246
Epoch: 36, Steps: 10 | Train Loss: 0.2066113 Vali Loss: 0.2104505 Test Loss: 0.9788487
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.00055
Epoch: 37 cost time: 0.4679560661315918
Epoch: 37, Steps: 10 | Train Loss: 0.2014575 Vali Loss: 0.2211164 Test Loss: 0.7924123
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.00055
Epoch: 38 cost time: 0.46045446395874023
Epoch: 38, Steps: 10 | Train Loss: 0.1976752 Vali Loss: 0.2092151 Test Loss: 0.8640705
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.00055
Epoch: 39 cost time: 0.5071685314178467
Epoch: 39, Steps: 10 | Train Loss: 0.2044842 Vali Loss: 0.2222315 Test Loss: 0.9985698
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.00055
Epoch: 40 cost time: 0.5003094673156738
Epoch: 40, Steps: 10 | Train Loss: 0.1933475 Vali Loss: 0.2697844 Test Loss: 0.7373917
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.00055
Epoch: 41 cost time: 0.46861767768859863
Epoch: 41, Steps: 10 | Train Loss: 0.2004121 Vali Loss: 0.2201561 Test Loss: 0.9104421
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.00055
Epoch: 42 cost time: 0.5209164619445801
Epoch: 42, Steps: 10 | Train Loss: 0.1915364 Vali Loss: 0.2540246 Test Loss: 0.8361304
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.00055
Epoch: 43 cost time: 0.462238073348999
Epoch: 43, Steps: 10 | Train Loss: 0.1881627 Vali Loss: 0.2651896 Test Loss: 0.8673397
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.00055
Epoch: 44 cost time: 0.5122280120849609
Epoch: 44, Steps: 10 | Train Loss: 0.1845621 Vali Loss: 0.2044947 Test Loss: 0.9028198
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.00055
Epoch: 45 cost time: 0.4608793258666992
Epoch: 45, Steps: 10 | Train Loss: 0.1908451 Vali Loss: 0.2166943 Test Loss: 0.8976173
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.00055
Epoch: 46 cost time: 0.4609375
Epoch: 46, Steps: 10 | Train Loss: 0.1881814 Vali Loss: 0.2479084 Test Loss: 0.8938587
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.00055
Epoch: 47 cost time: 0.4667026996612549
Epoch: 47, Steps: 10 | Train Loss: 0.1760586 Vali Loss: 0.2425466 Test Loss: 0.8702426
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.00055
Epoch: 48 cost time: 0.4645521640777588
Epoch: 48, Steps: 10 | Train Loss: 0.1796889 Vali Loss: 0.2455578 Test Loss: 0.9420922
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.00055
Epoch: 49 cost time: 0.49147629737854004
Epoch: 49, Steps: 10 | Train Loss: 0.1759195 Vali Loss: 0.2582948 Test Loss: 0.8427514
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.00055
Epoch: 50 cost time: 0.4645833969116211
Epoch: 50, Steps: 10 | Train Loss: 0.1738423 Vali Loss: 0.2721486 Test Loss: 0.9042783
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : 36_24_SPM_TST_custom_ftM_sl36_ll18_pl24_dm139_nh1_el1_dl1_df114_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 170
mse:0.7710028886795044, mae:0.5294721126556396, rse:0.4688258171081543
