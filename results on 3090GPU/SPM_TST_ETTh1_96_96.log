Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=101, c_out=7, checkpoints='./checkpoints/', d_ff=37, d_layers=1, d_model=50, data='ETTh1', data_path='ETTh1.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', dishts=1, distil=True, do_predict=False, dropout=0.3, e_layers=1, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, hidden_size=[33, 51], hidden_size1=3, hidden_size2=3, individual=0, is_training=1, itr=1, k=1.0, kernel_size=25, label_len=18, learning_rate=3e-05, loss='mse', lradj='type3', model='SPM_TST', model_id='96_96', moving_avg=25, n_heads=1, num_layers=3, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=8, pct_start=0.3, pred_len=96, random_seed=2021, revin=1, root_path='./dataset/', seq_len=96, stride=8, subtract_last=0, target='OT', test_flop=False, traffic=0, train_epochs=300, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : 96_96_SPM_TST_ETTh1_ftM_sl96_ll18_pl96_dm50_nh1_el1_dl1_df37_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
Epoch: 1 cost time: 2.0467019081115723
Epoch: 1, Steps: 83 | Train Loss: 0.5326156 Vali Loss: 1.0635138 Test Loss: 0.6376408
Validation loss decreased (inf --> 1.063514).  Saving model ...
Updating learning rate to 3e-05
Epoch: 2 cost time: 1.635528326034546
Epoch: 2, Steps: 83 | Train Loss: 0.3906309 Vali Loss: 0.7103122 Test Loss: 0.3921472
Validation loss decreased (1.063514 --> 0.710312).  Saving model ...
Updating learning rate to 3e-05
Epoch: 3 cost time: 1.655895709991455
Epoch: 3, Steps: 83 | Train Loss: 0.3582793 Vali Loss: 0.7034101 Test Loss: 0.3834628
Validation loss decreased (0.710312 --> 0.703410).  Saving model ...
Updating learning rate to 3e-05
Epoch: 4 cost time: 1.6753902435302734
Epoch: 4, Steps: 83 | Train Loss: 0.3502374 Vali Loss: 0.6899399 Test Loss: 0.3808275
Validation loss decreased (0.703410 --> 0.689940).  Saving model ...
Updating learning rate to 2.7000000000000002e-05
Epoch: 5 cost time: 1.5770394802093506
Epoch: 5, Steps: 83 | Train Loss: 0.3434810 Vali Loss: 0.6934910 Test Loss: 0.3774241
EarlyStopping counter: 1 out of 8
Updating learning rate to 2.43e-05
Epoch: 6 cost time: 1.583233118057251
Epoch: 6, Steps: 83 | Train Loss: 0.3395397 Vali Loss: 0.6928659 Test Loss: 0.3764548
EarlyStopping counter: 2 out of 8
Updating learning rate to 2.1870000000000002e-05
Epoch: 7 cost time: 1.5394575595855713
Epoch: 7, Steps: 83 | Train Loss: 0.3356648 Vali Loss: 0.6900760 Test Loss: 0.3736931
EarlyStopping counter: 3 out of 8
Updating learning rate to 1.9683e-05
Epoch: 8 cost time: 1.66495943069458
Epoch: 8, Steps: 83 | Train Loss: 0.3332608 Vali Loss: 0.6926301 Test Loss: 0.3728585
EarlyStopping counter: 4 out of 8
Updating learning rate to 1.77147e-05
Epoch: 9 cost time: 1.649977445602417
Epoch: 9, Steps: 83 | Train Loss: 0.3302691 Vali Loss: 0.6920556 Test Loss: 0.3725623
EarlyStopping counter: 5 out of 8
Updating learning rate to 1.5943230000000002e-05
Epoch: 10 cost time: 1.6588659286499023
Epoch: 10, Steps: 83 | Train Loss: 0.3286417 Vali Loss: 0.6887729 Test Loss: 0.3719258
Validation loss decreased (0.689940 --> 0.688773).  Saving model ...
Updating learning rate to 1.4348907000000003e-05
Epoch: 11 cost time: 1.6453769207000732
Epoch: 11, Steps: 83 | Train Loss: 0.3263623 Vali Loss: 0.6959471 Test Loss: 0.3711082
EarlyStopping counter: 1 out of 8
Updating learning rate to 1.2914016300000004e-05
Epoch: 12 cost time: 1.6769211292266846
Epoch: 12, Steps: 83 | Train Loss: 0.3245149 Vali Loss: 0.6873457 Test Loss: 0.3708017
Validation loss decreased (0.688773 --> 0.687346).  Saving model ...
Updating learning rate to 1.1622614670000003e-05
Epoch: 13 cost time: 1.7020606994628906
Epoch: 13, Steps: 83 | Train Loss: 0.3231837 Vali Loss: 0.6934367 Test Loss: 0.3709683
EarlyStopping counter: 1 out of 8
Updating learning rate to 1.0460353203000003e-05
Epoch: 14 cost time: 1.629575490951538
Epoch: 14, Steps: 83 | Train Loss: 0.3219430 Vali Loss: 0.6904695 Test Loss: 0.3703196
EarlyStopping counter: 2 out of 8
Updating learning rate to 9.414317882700003e-06
Epoch: 15 cost time: 1.756380558013916
Epoch: 15, Steps: 83 | Train Loss: 0.3203172 Vali Loss: 0.6920482 Test Loss: 0.3702740
EarlyStopping counter: 3 out of 8
Updating learning rate to 8.472886094430004e-06
Epoch: 16 cost time: 1.6413593292236328
Epoch: 16, Steps: 83 | Train Loss: 0.3192727 Vali Loss: 0.6933624 Test Loss: 0.3698185
EarlyStopping counter: 4 out of 8
Updating learning rate to 7.625597484987003e-06
Epoch: 17 cost time: 1.5696899890899658
Epoch: 17, Steps: 83 | Train Loss: 0.3184159 Vali Loss: 0.6900483 Test Loss: 0.3698418
EarlyStopping counter: 5 out of 8
Updating learning rate to 6.8630377364883025e-06
Epoch: 18 cost time: 1.645409345626831
Epoch: 18, Steps: 83 | Train Loss: 0.3176660 Vali Loss: 0.6909035 Test Loss: 0.3698324
EarlyStopping counter: 6 out of 8
Updating learning rate to 6.176733962839472e-06
Epoch: 19 cost time: 1.5471909046173096
Epoch: 19, Steps: 83 | Train Loss: 0.3166902 Vali Loss: 0.6916352 Test Loss: 0.3700905
EarlyStopping counter: 7 out of 8
Updating learning rate to 5.559060566555525e-06
Epoch: 20 cost time: 1.6052076816558838
Epoch: 20, Steps: 83 | Train Loss: 0.3166795 Vali Loss: 0.6917939 Test Loss: 0.3694569
EarlyStopping counter: 8 out of 8
Early stopping
>>>>>>>testing : 96_96_SPM_TST_ETTh1_ftM_sl96_ll18_pl96_dm50_nh1_el1_dl1_df37_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3708016276359558, mae:0.39457643032073975, rse:0.5777800679206848
