Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=449, c_out=7, checkpoints='./checkpoints/', d_ff=110, d_layers=1, d_model=51, data='ETTh1', data_path='ETTh1.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', dishts=0, distil=True, do_predict=False, dropout=0.3, e_layers=1, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, hidden_size=[23, 29], hidden_size1=3, hidden_size2=3, individual=0, is_training=1, itr=1, k=1.0, kernel_size=25, label_len=18, learning_rate=0.00033, loss='mse', lradj='type3', model='SPM_TST', model_id='96_192', moving_avg=25, n_heads=1, num_layers=3, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=8, pct_start=0.3, pred_len=192, random_seed=2021, revin=1, root_path='./dataset/', seq_len=96, stride=8, subtract_last=0, target='OT', test_flop=False, traffic=0, train_epochs=300, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : 96_192_SPM_TST_ETTh1_ftM_sl96_ll18_pl192_dm51_nh1_el1_dl1_df110_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2689
test 2689
Epoch: 1 cost time: 0.9435229301452637
Epoch: 1, Steps: 18 | Train Loss: 0.5801906 Vali Loss: 1.3400183 Test Loss: 0.6259464
Validation loss decreased (inf --> 1.340018).  Saving model ...
Updating learning rate to 0.00033
Epoch: 2 cost time: 0.714569091796875
Epoch: 2, Steps: 18 | Train Loss: 0.4798692 Vali Loss: 1.0795630 Test Loss: 0.4587471
Validation loss decreased (1.340018 --> 1.079563).  Saving model ...
Updating learning rate to 0.00033
Epoch: 3 cost time: 0.724320650100708
Epoch: 3, Steps: 18 | Train Loss: 0.4359887 Vali Loss: 1.0021179 Test Loss: 0.4192817
Validation loss decreased (1.079563 --> 1.002118).  Saving model ...
Updating learning rate to 0.00033
Epoch: 4 cost time: 0.7191369533538818
Epoch: 4, Steps: 18 | Train Loss: 0.4229217 Vali Loss: 0.9995654 Test Loss: 0.4282540
Validation loss decreased (1.002118 --> 0.999565).  Saving model ...
Updating learning rate to 0.000297
Epoch: 5 cost time: 0.7090466022491455
Epoch: 5, Steps: 18 | Train Loss: 0.4156348 Vali Loss: 0.9956515 Test Loss: 0.4064088
Validation loss decreased (0.999565 --> 0.995652).  Saving model ...
Updating learning rate to 0.0002673
Epoch: 6 cost time: 0.718254566192627
Epoch: 6, Steps: 18 | Train Loss: 0.4082836 Vali Loss: 0.9969013 Test Loss: 0.4084012
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.00024057000000000004
Epoch: 7 cost time: 0.7075772285461426
Epoch: 7, Steps: 18 | Train Loss: 0.4035864 Vali Loss: 0.9973952 Test Loss: 0.4041191
EarlyStopping counter: 2 out of 8
Updating learning rate to 0.000216513
Epoch: 8 cost time: 0.723160982131958
Epoch: 8, Steps: 18 | Train Loss: 0.3998332 Vali Loss: 0.9814504 Test Loss: 0.4058627
Validation loss decreased (0.995652 --> 0.981450).  Saving model ...
Updating learning rate to 0.00019486170000000003
Epoch: 9 cost time: 0.7339732646942139
Epoch: 9, Steps: 18 | Train Loss: 0.3956209 Vali Loss: 0.9882261 Test Loss: 0.3998830
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.00017537553000000002
Epoch: 10 cost time: 0.7285487651824951
Epoch: 10, Steps: 18 | Train Loss: 0.3934247 Vali Loss: 0.9837878 Test Loss: 0.4064180
EarlyStopping counter: 2 out of 8
Updating learning rate to 0.00015783797700000003
Epoch: 11 cost time: 0.5950329303741455
Epoch: 11, Steps: 18 | Train Loss: 0.3904486 Vali Loss: 0.9785118 Test Loss: 0.4016150
Validation loss decreased (0.981450 --> 0.978512).  Saving model ...
Updating learning rate to 0.00014205417930000002
Epoch: 12 cost time: 0.7757952213287354
Epoch: 12, Steps: 18 | Train Loss: 0.3869914 Vali Loss: 0.9992273 Test Loss: 0.4000165
EarlyStopping counter: 1 out of 8
Updating learning rate to 0.00012784876137000002
Epoch: 13 cost time: 0.8115191459655762
Epoch: 13, Steps: 18 | Train Loss: 0.3854233 Vali Loss: 0.9900168 Test Loss: 0.4033578
EarlyStopping counter: 2 out of 8
Updating learning rate to 0.00011506388523300003
Epoch: 14 cost time: 0.8833966255187988
Epoch: 14, Steps: 18 | Train Loss: 0.3836953 Vali Loss: 0.9952865 Test Loss: 0.4079412
EarlyStopping counter: 3 out of 8
Updating learning rate to 0.00010355749670970002
Epoch: 15 cost time: 0.8215389251708984
Epoch: 15, Steps: 18 | Train Loss: 0.3811535 Vali Loss: 0.9932489 Test Loss: 0.4049004
EarlyStopping counter: 4 out of 8
Updating learning rate to 9.320174703873003e-05
Epoch: 16 cost time: 0.7075426578521729
Epoch: 16, Steps: 18 | Train Loss: 0.3793510 Vali Loss: 0.9910496 Test Loss: 0.4024755
EarlyStopping counter: 5 out of 8
Updating learning rate to 8.388157233485703e-05
Epoch: 17 cost time: 0.7641422748565674
Epoch: 17, Steps: 18 | Train Loss: 0.3772714 Vali Loss: 1.0004032 Test Loss: 0.4017861
EarlyStopping counter: 6 out of 8
Updating learning rate to 7.549341510137133e-05
Epoch: 18 cost time: 0.7600967884063721
Epoch: 18, Steps: 18 | Train Loss: 0.3758445 Vali Loss: 0.9967025 Test Loss: 0.4093890
EarlyStopping counter: 7 out of 8
Updating learning rate to 6.794407359123419e-05
Epoch: 19 cost time: 0.7757964134216309
Epoch: 19, Steps: 18 | Train Loss: 0.3746598 Vali Loss: 1.0002284 Test Loss: 0.4060958
EarlyStopping counter: 8 out of 8
Early stopping
>>>>>>>testing : 96_192_SPM_TST_ETTh1_ftM_sl96_ll18_pl192_dm51_nh1_el1_dl1_df110_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
mse:0.40161508321762085, mae:0.4123694896697998, rse:0.6140419840812683
