Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=493, c_out=7, checkpoints='./checkpoints/', d_ff=120, d_layers=1, d_model=231, data='ETTm2', data_path='ETTm2.csv', dec_in=7, decomposition=0, des='Exp', devices='0,1,2,3', dishts=1, distil=True, do_predict=False, dropout=0.3, e_layers=1, embed='timeF', embed_type=0, enc_in=7, factor=1, fc_dropout=0.3, features='M', freq='h', gpu=0, head_dropout=0.0, hidden_size=[19, 12], hidden_size1=3, hidden_size2=3, individual=0, is_training=1, itr=1, k=1.0, kernel_size=25, label_len=18, learning_rate=0.00882, loss='mse', lradj='type3', model='SPM_TST', model_id='96_720', moving_avg=25, n_heads=1, num_layers=3, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=20, pct_start=0.3, pred_len=720, random_seed=2021, revin=1, root_path='./dataset/', seq_len=96, stride=8, subtract_last=0, target='OT', test_flop=False, topk=49, traffic=0, train_epochs=300, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : 96_720_SPM_TST_ETTm2_ftM_sl96_ll18_pl720_dm231_nh1_el1_dl1_df120_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
Epoch: 1 cost time: 4.710969686508179
Epoch: 1, Steps: 68 | Train Loss: 0.5782497 Vali Loss: 0.2862864 Test Loss: 0.3773104
Validation loss decreased (inf --> 0.286286).  Saving model ...
Updating learning rate to 0.00882
Epoch: 2 cost time: 4.177197217941284
Epoch: 2, Steps: 68 | Train Loss: 0.5933842 Vali Loss: 0.3174662 Test Loss: 0.4168793
EarlyStopping counter: 1 out of 20
Updating learning rate to 0.00882
Epoch: 3 cost time: 3.7216975688934326
Epoch: 3, Steps: 68 | Train Loss: 0.5833769 Vali Loss: 0.3022885 Test Loss: 0.4044637
EarlyStopping counter: 2 out of 20
Updating learning rate to 0.00882
Epoch: 4 cost time: 5.656095027923584
Epoch: 4, Steps: 68 | Train Loss: 0.5673469 Vali Loss: 0.3046422 Test Loss: 0.4097362
EarlyStopping counter: 3 out of 20
Updating learning rate to 0.007938
Epoch: 5 cost time: 4.059870004653931
Epoch: 5, Steps: 68 | Train Loss: 0.5457325 Vali Loss: 0.2986308 Test Loss: 0.4029665
EarlyStopping counter: 4 out of 20
Updating learning rate to 0.0071442
Epoch: 6 cost time: 4.5805768966674805
Epoch: 6, Steps: 68 | Train Loss: 0.5292031 Vali Loss: 0.3020790 Test Loss: 0.4046877
EarlyStopping counter: 5 out of 20
Updating learning rate to 0.00642978
Epoch: 7 cost time: 4.351793050765991
Epoch: 7, Steps: 68 | Train Loss: 0.5139525 Vali Loss: 0.2969916 Test Loss: 0.4009029
EarlyStopping counter: 6 out of 20
Updating learning rate to 0.005786802
Epoch: 8 cost time: 5.482945680618286
Epoch: 8, Steps: 68 | Train Loss: 0.5038220 Vali Loss: 0.3012370 Test Loss: 0.4047166
EarlyStopping counter: 7 out of 20
Updating learning rate to 0.005208121800000001
Epoch: 9 cost time: 6.301457405090332
Epoch: 9, Steps: 68 | Train Loss: 0.4981833 Vali Loss: 0.3012954 Test Loss: 0.4059035
EarlyStopping counter: 8 out of 20
Updating learning rate to 0.004687309620000001
Epoch: 10 cost time: 4.619065284729004
Epoch: 10, Steps: 68 | Train Loss: 0.4920319 Vali Loss: 0.3017849 Test Loss: 0.4088911
EarlyStopping counter: 9 out of 20
Updating learning rate to 0.004218578658000001
Epoch: 11 cost time: 4.474363088607788
Epoch: 11, Steps: 68 | Train Loss: 0.4884115 Vali Loss: 0.3005997 Test Loss: 0.4032724
EarlyStopping counter: 10 out of 20
Updating learning rate to 0.003796720792200001
Epoch: 12 cost time: 4.339450120925903
Epoch: 12, Steps: 68 | Train Loss: 0.4819587 Vali Loss: 0.3013550 Test Loss: 0.4086091
EarlyStopping counter: 11 out of 20
Updating learning rate to 0.0034170487129800008
Epoch: 13 cost time: 5.742157459259033
Epoch: 13, Steps: 68 | Train Loss: 0.4738643 Vali Loss: 0.3064626 Test Loss: 0.4138049
EarlyStopping counter: 12 out of 20
Updating learning rate to 0.003075343841682001
Epoch: 14 cost time: 4.797372341156006
Epoch: 14, Steps: 68 | Train Loss: 0.4675363 Vali Loss: 0.3035401 Test Loss: 0.4157590
EarlyStopping counter: 13 out of 20
Updating learning rate to 0.0027678094575138003
Epoch: 15 cost time: 4.377525568008423
Epoch: 15, Steps: 68 | Train Loss: 0.4636744 Vali Loss: 0.3031251 Test Loss: 0.4102034
EarlyStopping counter: 14 out of 20
Updating learning rate to 0.002491028511762421
Epoch: 16 cost time: 4.6514246463775635
Epoch: 16, Steps: 68 | Train Loss: 0.4570600 Vali Loss: 0.3034859 Test Loss: 0.4192670
EarlyStopping counter: 15 out of 20
Updating learning rate to 0.0022419256605861787
Epoch: 17 cost time: 5.680575609207153
Epoch: 17, Steps: 68 | Train Loss: 0.4536584 Vali Loss: 0.3030679 Test Loss: 0.4122699
EarlyStopping counter: 16 out of 20
Updating learning rate to 0.002017733094527561
Epoch: 18 cost time: 6.26678729057312
Epoch: 18, Steps: 68 | Train Loss: 0.4492377 Vali Loss: 0.3074704 Test Loss: 0.4169743
EarlyStopping counter: 17 out of 20
Updating learning rate to 0.0018159597850748047
Epoch: 19 cost time: 4.953053951263428
Epoch: 19, Steps: 68 | Train Loss: 0.4447817 Vali Loss: 0.3033369 Test Loss: 0.4081922
EarlyStopping counter: 18 out of 20
Updating learning rate to 0.0016343638065673242
Epoch: 20 cost time: 4.0008087158203125
Epoch: 20, Steps: 68 | Train Loss: 0.4414817 Vali Loss: 0.3084809 Test Loss: 0.4164836
EarlyStopping counter: 19 out of 20
Updating learning rate to 0.001470927425910592
Epoch: 21 cost time: 4.1240012645721436
Epoch: 21, Steps: 68 | Train Loss: 0.4376310 Vali Loss: 0.3063280 Test Loss: 0.4149479
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : 96_720_SPM_TST_ETTm2_ftM_sl96_ll18_pl720_dm231_nh1_el1_dl1_df120_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.37731069326400757, mae:0.38739633560180664, rse:0.49018919467926025
